{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ingest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading local cache file Outpatient.pkl\n"
     ]
    }
   ],
   "source": [
    "outpatient = ingest.get_cache_data(\"Outpatient\", \"Outpatient.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient.dropna(subset=['CLM_PMT_AMT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790790\n",
      "Index(['DESYNPUF_ID', 'CLM_ID', 'SEGMENT', 'CLM_FROM_DT', 'CLM_THRU_DT',\n",
      "       'PRVDR_NUM', 'CLM_PMT_AMT', 'NCH_PRMRY_PYR_CLM_PD_AMT', 'AT_PHYSN_NPI',\n",
      "       'OP_PHYSN_NPI', 'OT_PHYSN_NPI', 'NCH_BENE_BLOOD_DDCTBL_LBLTY_AM',\n",
      "       'ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3', 'ICD9_DGNS_CD_4',\n",
      "       'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7', 'ICD9_DGNS_CD_8',\n",
      "       'ICD9_DGNS_CD_9', 'ICD9_DGNS_CD_10', 'ICD9_PRCDR_CD_1',\n",
      "       'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3', 'ICD9_PRCDR_CD_4',\n",
      "       'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6', 'NCH_BENE_PTB_DDCTBL_AMT',\n",
      "       'NCH_BENE_PTB_COINSRNC_AMT', 'ADMTNG_ICD9_DGNS_CD', 'HCPCS_CD_1',\n",
      "       'HCPCS_CD_2', 'HCPCS_CD_3', 'HCPCS_CD_4', 'HCPCS_CD_5', 'HCPCS_CD_6',\n",
      "       'HCPCS_CD_7', 'HCPCS_CD_8', 'HCPCS_CD_9', 'HCPCS_CD_10', 'HCPCS_CD_11',\n",
      "       'HCPCS_CD_12', 'HCPCS_CD_13', 'HCPCS_CD_14', 'HCPCS_CD_15',\n",
      "       'HCPCS_CD_16', 'HCPCS_CD_17', 'HCPCS_CD_18', 'HCPCS_CD_19',\n",
      "       'HCPCS_CD_20', 'HCPCS_CD_21', 'HCPCS_CD_22', 'HCPCS_CD_23',\n",
      "       'HCPCS_CD_24', 'HCPCS_CD_25', 'HCPCS_CD_26', 'HCPCS_CD_27',\n",
      "       'HCPCS_CD_28', 'HCPCS_CD_29', 'HCPCS_CD_30', 'HCPCS_CD_31',\n",
      "       'HCPCS_CD_32', 'HCPCS_CD_33', 'HCPCS_CD_34', 'HCPCS_CD_35',\n",
      "       'HCPCS_CD_36', 'HCPCS_CD_37', 'HCPCS_CD_38', 'HCPCS_CD_39',\n",
      "       'HCPCS_CD_40', 'HCPCS_CD_41', 'HCPCS_CD_42', 'HCPCS_CD_43',\n",
      "       'HCPCS_CD_44', 'HCPCS_CD_45', 'BENE_BIRTH_DT', 'BENE_SEX_IDENT_CD',\n",
      "       'SP_STATE_CODE', 'BENE_COUNTY_CD'],\n",
      "      dtype='object')\n",
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "790785    2\n",
      "790786    2\n",
      "790787    2\n",
      "790788    2\n",
      "790789    2\n",
      "Name: BENE_SEX_IDENT_CD, Length: 790790, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(len(outpatient))\n",
    "print(outpatient.columns)\n",
    "print(outpatient['BENE_SEX_IDENT_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sets_dict = {'BIRTH_DATE': ['BENE_BIRTH_DT'],\n",
    "    'SEX': ['BENE_SEX_IDENT_CD'],\n",
    "    'State': ['SP_STATE_CODE'],\n",
    "    'County': ['BENE_COUNTY_CD'], \n",
    "    'clm_dates': ['CLM_FROM_DT', 'CLM_THRU_DT'],\n",
    "    'provider': ['PRVDR_NUM'],\n",
    "    'DGNS_CD': ['ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3',\n",
    "    'ICD9_DGNS_CD_4', 'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7',\n",
    "    'ICD9_DGNS_CD_8', 'ICD9_DGNS_CD_9','ICD9_DGNS_CD_10'],\n",
    "    'PRDCR_CD': ['ICD9_PRCDR_CD_1', 'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3',\n",
    "    'ICD9_PRCDR_CD_4', 'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6'],\n",
    "    'HCPCS_CD': ['HCPCS_CD_1', 'HCPCS_CD_2', 'HCPCS_CD_3', 'HCPCS_CD_4',\n",
    "    'HCPCS_CD_5', 'HCPCS_CD_6', 'HCPCS_CD_7', 'HCPCS_CD_8', 'HCPCS_CD_9',\n",
    "    'HCPCS_CD_10', 'HCPCS_CD_11', 'HCPCS_CD_12', 'HCPCS_CD_13', 'HCPCS_CD_14',\n",
    "    'HCPCS_CD_15', 'HCPCS_CD_16', 'HCPCS_CD_17', 'HCPCS_CD_18', 'HCPCS_CD_19',\n",
    "    'HCPCS_CD_20', 'HCPCS_CD_21', 'HCPCS_CD_22', 'HCPCS_CD_23', 'HCPCS_CD_24',\n",
    "    'HCPCS_CD_25', 'HCPCS_CD_26', 'HCPCS_CD_27', 'HCPCS_CD_28', 'HCPCS_CD_29',\n",
    "    'HCPCS_CD_30', 'HCPCS_CD_31', 'HCPCS_CD_32', 'HCPCS_CD_33', 'HCPCS_CD_34',\n",
    "    'HCPCS_CD_35', 'HCPCS_CD_36', 'HCPCS_CD_37', 'HCPCS_CD_38', 'HCPCS_CD_39',\n",
    "    'HCPCS_CD_40', 'HCPCS_CD_41', 'HCPCS_CD_42', 'HCPCS_CD_43', 'HCPCS_CD_44',\n",
    "    'HCPCS_CD_45']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "def TFIDF_Matrix3(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that comprise a \"sentence\" using the first three characters of each word\n",
    "    #Returns a TFIDF matrix\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    if len(columns) > 1:\n",
    "        values = df[columns].values.tolist()\n",
    "\n",
    "        for sentence in values:\n",
    "            s = ''\n",
    "            for word in sentence:\n",
    "                if len(s) == 0:\n",
    "                    if isnan(word):\n",
    "                        s = 'None, '\n",
    "                    else:\n",
    "                        s = str(word)[:3]+' ' #Add [:3] after str(word) to truncate to the first 3 characters\n",
    "                else:\n",
    "                    if isnan(word):\n",
    "                        s += 'None, '\n",
    "                    else:\n",
    "                        s += str(word)[:3]+' ' #Add [:3] after str(word) to truncate to the first 3 characters\n",
    "            corpus.append(s)\n",
    "\n",
    "    else:\n",
    "        values = df[columns].values.tolist()\n",
    "        for word in values:\n",
    "            if isnan(word[0]):\n",
    "                corpus.append('None')\n",
    "            else:\n",
    "                corpus.append(word[0][:3]) #Add [:3] after word[0] to truncate to the first 3 characters\n",
    "\n",
    "    return  np.nan_to_num(TfidfVectorizer(stop_words=['None']).fit_transform(corpus))\n",
    "\n",
    "def TFIDF_Matrix(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that comprise a \"sentence\" using the complete \"word\"\n",
    "    #Returns a TFIDF matrix\n",
    "\n",
    "    print(columns)\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    if len(columns) > 1:\n",
    "        values = df[columns].values.tolist()\n",
    "\n",
    "        for sentence in values:\n",
    "            s = ''\n",
    "            for word in sentence:\n",
    "                if len(s) == 0:\n",
    "                    if isnan(word):\n",
    "                        s = 'None, '\n",
    "                    else:\n",
    "                        s = str(word)+' '\n",
    "                else:\n",
    "                    if isnan(word):\n",
    "                        s += 'None, '\n",
    "                    else:\n",
    "                        s += str(word)+' '\n",
    "            corpus.append(s)\n",
    "\n",
    "    else:\n",
    "        values = df[columns].values.tolist()\n",
    "        for word in values:\n",
    "            if isnan(word[0]):\n",
    "                corpus.append('None')\n",
    "            else:\n",
    "                corpus.append(word[0])\n",
    "\n",
    "    return  np.nan_to_num(TfidfVectorizer(stop_words=['None']).fit_transform(corpus))\n",
    "\n",
    "def Date_Year(df, columns):\n",
    "\n",
    "    df['year'] = pd.DatetimeIndex(df[columns[0]]).year\n",
    "\n",
    "    return np.nan_to_num(np.array(df['year'].values.tolist()).reshape(len(df),1))\n",
    "\n",
    "def Date_Diff(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that are a start date and end date\n",
    "    #Returns the difference between the two dates\n",
    "\n",
    "    values = df[columns]\n",
    "\n",
    "    values['date_diff'] = (df[columns[1]] - df[columns[0]])  / np.timedelta64(1, 'D')\n",
    "\n",
    "    return  np.nan_to_num(np.array(values['date_diff'].values.tolist()).reshape(len(values),1))\n",
    "    \n",
    "def Passthrough(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that need to be turned into a list\n",
    "    #Returns list of values from columns\n",
    "    \n",
    "    df[columns[0]] = pd.to_numeric(df[columns[0]], errors='coerce').astype('Int64')\n",
    "\n",
    "    return np.nan_to_num(np.array(df[columns].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SP_STATE_CODE']\n",
      "['BENE_COUNTY_CD']\n"
     ]
    }
   ],
   "source": [
    "column_sets_matrix_dict = {}\n",
    "for key, value in column_sets_dict.items():\n",
    "    if key in ['provider', 'NPI', 'admit_code', 'claim_discharge_code', 'DGNS_CD', 'PRDCR_CD', 'HCPCS_CD']:\n",
    "        column_sets_matrix_dict[key] = TFIDF_Matrix3(outpatient, value)\n",
    "    elif key in ['State', 'County']:\n",
    "        column_sets_matrix_dict[key] = TFIDF_Matrix(outpatient, value)\n",
    "    elif key in ['clm_dates', 'admit_dates']:\n",
    "        column_sets_matrix_dict[key] = Date_Diff(outpatient, value)\n",
    "    elif key in ['BIRTH_DATE']:\n",
    "        column_sets_matrix_dict[key] = Date_Year(outpatient, value)\n",
    "    else:\n",
    "        column_sets_matrix_dict[key] = Passthrough(outpatient, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_vectors_dictionary-truncated.txt\", \"wb\") as f:\n",
    "    pickle.dump(column_sets_matrix_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
