{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading local cache file Outpatient.pkl\n"
     ]
    }
   ],
   "source": [
    "outpatient = ingest.get_cache_data(\"Outpatient\", \"Outpatient.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient.dropna(subset=['CLM_PMT_AMT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790790\n"
     ]
    }
   ],
   "source": [
    "print(len(outpatient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sets_dict = {'clm_dates': ['CLM_FROM_DT', 'CLM_THRU_DT'],\n",
    "    'provider': ['PRVDR_NUM'],\n",
    "    'DGNS_CD': ['ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3',\n",
    "    'ICD9_DGNS_CD_4', 'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7',\n",
    "    'ICD9_DGNS_CD_8', 'ICD9_DGNS_CD_9','ICD9_DGNS_CD_10'],\n",
    "    'PRDCR_CD': ['ICD9_PRCDR_CD_1', 'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3',\n",
    "    'ICD9_PRCDR_CD_4', 'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6'],\n",
    "    'HCPCS_CD': ['HCPCS_CD_1', 'HCPCS_CD_2', 'HCPCS_CD_3', 'HCPCS_CD_4',\n",
    "    'HCPCS_CD_5', 'HCPCS_CD_6', 'HCPCS_CD_7', 'HCPCS_CD_8', 'HCPCS_CD_9',\n",
    "    'HCPCS_CD_10', 'HCPCS_CD_11', 'HCPCS_CD_12', 'HCPCS_CD_13', 'HCPCS_CD_14',\n",
    "    'HCPCS_CD_15', 'HCPCS_CD_16', 'HCPCS_CD_17', 'HCPCS_CD_18', 'HCPCS_CD_19',\n",
    "    'HCPCS_CD_20', 'HCPCS_CD_21', 'HCPCS_CD_22', 'HCPCS_CD_23', 'HCPCS_CD_24',\n",
    "    'HCPCS_CD_25', 'HCPCS_CD_26', 'HCPCS_CD_27', 'HCPCS_CD_28', 'HCPCS_CD_29',\n",
    "    'HCPCS_CD_30', 'HCPCS_CD_31', 'HCPCS_CD_32', 'HCPCS_CD_33', 'HCPCS_CD_34',\n",
    "    'HCPCS_CD_35', 'HCPCS_CD_36', 'HCPCS_CD_37', 'HCPCS_CD_38', 'HCPCS_CD_39',\n",
    "    'HCPCS_CD_40', 'HCPCS_CD_41', 'HCPCS_CD_42', 'HCPCS_CD_43', 'HCPCS_CD_44',\n",
    "    'HCPCS_CD_45']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "def TFIDF_Matrix(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that comprise a \"sentence\"\n",
    "    #Returns a TFIDF matrix\n",
    "\n",
    "    print('start')\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    if len(columns) > 1:\n",
    "        values = df[columns].values.tolist()\n",
    "\n",
    "        for sentence in values:\n",
    "            s = ''\n",
    "            for word in sentence:\n",
    "                if len(s) == 0:\n",
    "                    if isnan(word):\n",
    "                        s = 'None, '\n",
    "                    else:\n",
    "                        s = str(word)[:3]+' ' #Add [:3] after str(word) to truncate to the first 3 characters\n",
    "                else:\n",
    "                    if isnan(word):\n",
    "                        s += 'None, '\n",
    "                    else:\n",
    "                        s += str(word)[:3]+' ' #Add [:3] after str(word) to truncate to the first 3 characters\n",
    "            corpus.append(s)\n",
    "\n",
    "    else:\n",
    "        values = df[columns].values.tolist()\n",
    "        for word in values:\n",
    "            if isnan(word[0]):\n",
    "                corpus.append('None')\n",
    "            else:\n",
    "                corpus.append(word[0][:3]) #Add [:3] after word[0] to truncate to the first 3 characters\n",
    "    \n",
    "    print(corpus[:10])\n",
    "\n",
    "    return  TfidfVectorizer(stop_words=['None']).fit_transform(corpus)\n",
    "\n",
    "def Date_Diff(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that are a start date and end date\n",
    "    #Returns the difference between the two dates\n",
    "\n",
    "    values = df[columns]\n",
    "\n",
    "    values['date_diff'] = (df[columns[1]] - df[columns[0]])\n",
    "\n",
    "    return  np.array(values['date_diff'].values.tolist()).reshape(len(values),1)\n",
    "    \n",
    "def Passthrough(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that need to be turned into a list\n",
    "    #Returns list of values from columns\n",
    "    \n",
    "    return np.array(df[columns].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "['260', '390', '393', '390', '520', '521', '521', '520', '390', '390']\n",
      "start\n",
      "['V58 None, None, None, None, None, None, None, None, None, ', 'V58 V58 272 318 V58 427 None, None, None, None, ', '959 E91 401 None, None, None, None, None, None, None, ', '789 V58 V12 None, None, None, None, None, None, None, ', '600 None, None, None, None, None, None, None, None, None, ', '611 None, None, None, None, None, None, None, None, None, ', '272 None, None, None, None, None, None, None, None, None, ', 'V82 None, None, None, None, None, None, None, None, None, ', 'None, None, None, None, None, None, None, None, None, None, ', '790 None, None, None, None, None, None, None, None, None, ']\n",
      "start\n",
      "['None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ', 'None, None, None, None, None, None, ']\n",
      "start\n",
      "['856 841 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '856 800 800 823 963 870 850 800 840 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '711 784 940 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '364 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '768 823 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', 'G02 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '364 800 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', 'G02 770 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '735 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ', '364 850 None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, ']\n"
     ]
    }
   ],
   "source": [
    "column_sets_matrix_dict = {}\n",
    "for key, value in column_sets_dict.items():\n",
    "    if key in ['provider', 'NPI', 'admit_code', 'claim_discharge_code', 'DGNS_CD', 'PRDCR_CD', 'HCPCS_CD']:\n",
    "        column_sets_matrix_dict[key] = TFIDF_Matrix(outpatient, value)\n",
    "    elif key in ['clm_dates', 'admit_dates']:\n",
    "        column_sets_matrix_dict[key] = Date_Diff(outpatient, value)\n",
    "    else:\n",
    "        column_sets_matrix_dict[key] = Passthrough(outpatient, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_vectors_dictionary-truncated.txt\", \"wb\") as f:\n",
    "    pickle.dump(column_sets_matrix_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
