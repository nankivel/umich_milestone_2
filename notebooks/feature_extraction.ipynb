{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from src.dataset import get_cache_data\n",
    "\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient_path = (\n",
    "    Path(module_path).expanduser().joinpath(\"data\").joinpath(\"raw\").joinpath(\"outpatient.pkl\")\n",
    ")\n",
    "outpatient = get_cache_data(\"outpatient\", outpatient_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient.dropna(subset=['CLM_PMT_AMT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sets_dict = {'BIRTH_DATE': ['BENE_BIRTH_DT'],\n",
    "    'SEX': ['BENE_SEX_IDENT_CD'],\n",
    "    'State': ['SP_STATE_CODE'],\n",
    "    'County': ['BENE_COUNTY_CD'], \n",
    "    'clm_dates': ['CLM_FROM_DT', 'CLM_THRU_DT'],\n",
    "    'provider': ['PRVDR_NUM'],\n",
    "    'DGNS_CD': ['ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3',\n",
    "    'ICD9_DGNS_CD_4', 'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7',\n",
    "    'ICD9_DGNS_CD_8', 'ICD9_DGNS_CD_9','ICD9_DGNS_CD_10'],\n",
    "    'PRDCR_CD': ['ICD9_PRCDR_CD_1', 'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3',\n",
    "    'ICD9_PRCDR_CD_4', 'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6'],\n",
    "    'HCPCS_CD': ['HCPCS_CD_1', 'HCPCS_CD_2', 'HCPCS_CD_3', 'HCPCS_CD_4',\n",
    "    'HCPCS_CD_5', 'HCPCS_CD_6', 'HCPCS_CD_7', 'HCPCS_CD_8', 'HCPCS_CD_9',\n",
    "    'HCPCS_CD_10', 'HCPCS_CD_11', 'HCPCS_CD_12', 'HCPCS_CD_13', 'HCPCS_CD_14',\n",
    "    'HCPCS_CD_15', 'HCPCS_CD_16', 'HCPCS_CD_17', 'HCPCS_CD_18', 'HCPCS_CD_19',\n",
    "    'HCPCS_CD_20', 'HCPCS_CD_21', 'HCPCS_CD_22', 'HCPCS_CD_23', 'HCPCS_CD_24',\n",
    "    'HCPCS_CD_25', 'HCPCS_CD_26', 'HCPCS_CD_27', 'HCPCS_CD_28', 'HCPCS_CD_29',\n",
    "    'HCPCS_CD_30', 'HCPCS_CD_31', 'HCPCS_CD_32', 'HCPCS_CD_33', 'HCPCS_CD_34',\n",
    "    'HCPCS_CD_35', 'HCPCS_CD_36', 'HCPCS_CD_37', 'HCPCS_CD_38', 'HCPCS_CD_39',\n",
    "    'HCPCS_CD_40', 'HCPCS_CD_41', 'HCPCS_CD_42', 'HCPCS_CD_43', 'HCPCS_CD_44',\n",
    "    'HCPCS_CD_45']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "def TFIDF_Matrix_len_char(df, columns, len_char):\n",
    "    #Takes in a dataframe, and a list of columns that comprise a \"sentence\" using the first three characters of each word\n",
    "    #Returns a TFIDF matrix\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    if len(columns) > 1:\n",
    "        values = df[columns].values.tolist()\n",
    "\n",
    "        for sentence in values:\n",
    "            s = ''\n",
    "            for word in sentence:\n",
    "                if len(s) == 0:\n",
    "                    if isnan(word):\n",
    "                        s = 'None, '\n",
    "                    else:\n",
    "                        s = str(word)[:len_char]+' ' #Add [:3] after str(word) to truncate to the first 3 characters\n",
    "                else:\n",
    "                    if isnan(word):\n",
    "                        s += 'None, '\n",
    "                    else:\n",
    "                        s += str(word)[:len_char]+' ' #Add [:3] after str(word) to truncate to the first 3 characters\n",
    "            corpus.append(s)\n",
    "\n",
    "    else:\n",
    "        values = df[columns].values.tolist()\n",
    "        for word in values:\n",
    "            if isnan(word[0]):\n",
    "                corpus.append('None')\n",
    "            else:\n",
    "                corpus.append(word[0][:len_char]) #Add [:3] after word[0] to truncate to the first 3 characters\n",
    "    \n",
    "    a = TfidfVectorizer(stop_words=['None']).fit_transform(corpus)\n",
    "\n",
    "    return  np.nan_to_num(a), np.nan_to_num(np.sum(a,axis=1))\n",
    "\n",
    "def TFIDF_Matrix(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that comprise a \"sentence\" using the complete \"word\"\n",
    "    #Returns a TFIDF matrix\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    if len(columns) > 1:\n",
    "        values = df[columns].values.tolist()\n",
    "\n",
    "        for sentence in values:\n",
    "            s = ''\n",
    "            for word in sentence:\n",
    "                if len(s) == 0:\n",
    "                    if isnan(word):\n",
    "                        s = 'None, '\n",
    "                    else:\n",
    "                        s = str(word)+' '\n",
    "                else:\n",
    "                    if isnan(word):\n",
    "                        s += 'None, '\n",
    "                    else:\n",
    "                        s += str(word)+' '\n",
    "            corpus.append(s)\n",
    "\n",
    "    else:\n",
    "        values = df[columns].values.tolist()\n",
    "        for word in values:\n",
    "            if isnan(word[0]):\n",
    "                corpus.append('None')\n",
    "            else:\n",
    "                corpus.append(word[0])\n",
    "\n",
    "    a = TfidfVectorizer(stop_words=['None']).fit_transform(corpus)\n",
    "\n",
    "    return  np.nan_to_num(a)\n",
    "\n",
    "def Date_Year(df, columns):\n",
    "\n",
    "    df['year'] = pd.DatetimeIndex(df[columns[0]]).year\n",
    "\n",
    "    return np.nan_to_num(np.array(df['year'].values.tolist()).reshape(len(df),1))\n",
    "\n",
    "def Date_Diff(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that are a start date and end date\n",
    "    #Returns the difference between the two dates\n",
    "\n",
    "    values = df[columns]\n",
    "\n",
    "    values['date_diff'] = (df[columns[1]] - df[columns[0]])  / np.timedelta64(1, 'D')\n",
    "\n",
    "    return  np.nan_to_num(np.array(values['date_diff'].values.tolist()).reshape(len(values),1) / np.array(values['date_diff'].values.tolist()).reshape(len(values),1).max(axis=0))\n",
    "    \n",
    "def Passthrough(df, columns):\n",
    "    #Takes in a dataframe, and a list of columns that need to be turned into a list\n",
    "    #Returns list of values from columns\n",
    "    \n",
    "    df[columns[0]] = pd.to_numeric(df[columns[0]], errors='coerce').astype('Int64')\n",
    "\n",
    "    return np.nan_to_num(np.array(df[columns].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sets_matrix_dict = {}\n",
    "for key, value in column_sets_dict.items():\n",
    "    if key in ['provider', 'NPI', 'admit_code', 'claim_discharge_code', 'DGNS_CD', 'PRDCR_CD', 'HCPCS_CD']:\n",
    "        column_sets_matrix_dict[key], column_sets_matrix_dict[key+'_count'] = TFIDF_Matrix_len_char(outpatient, value, 3)\n",
    "    elif key in ['State', 'County']:\n",
    "        column_sets_matrix_dict[key] = TFIDF_Matrix(outpatient, value)\n",
    "    elif key in ['clm_dates', 'admit_dates']:\n",
    "        column_sets_matrix_dict[key] = Date_Diff(outpatient, value)\n",
    "    elif key in ['BIRTH_DATE']:\n",
    "        column_sets_matrix_dict[key] = Date_Year(outpatient, value)\n",
    "    else:\n",
    "        column_sets_matrix_dict[key] = Passthrough(outpatient, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_dict_path = (\n",
    "    Path(\"data\")\n",
    "    .expanduser()\n",
    "    .joinpath(\"features\")\n",
    "    .joinpath(\"feature_vectors_dictionary-truncated.pkl\")\n",
    ")\n",
    "with open(feature_vectors_dict_path, \"wb\") as f:\n",
    "    pickle.dump(column_sets_matrix_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_sets_matrix_dict['HCPCS_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
